{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4627f3d0",
   "metadata": {},
   "source": [
    "#  ATLAS/ICESat-2 Monthly Gridded Sea Ice Freeboard\n",
    "*Introduce dataset here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8b3bc3",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#this cell will load dependencies for running the notebook in Google Colab\n",
    "#this cell may take a while to run\n",
    "import sys\n",
    "\n",
    "#if code is running in google colab, run these cells to install neccessary libraries\n",
    "if 'google.colab' in sys.modules: \n",
    "    !apt-get install -qq libgdal-dev libproj-dev\n",
    "    !pip install --no-binary shapely shapely --force\n",
    "    !pip install -q pyproj\n",
    "    !pip install cartopy\n",
    "    !pip install netcdf4\n",
    "    !pip install xarray==0.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dab7d0",
   "metadata": {},
   "source": [
    "# Import notebook dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b237e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy.ma as ma\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pyproj\n",
    "from glob import glob\n",
    "from textwrap import wrap\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "#axes needed for plotting\n",
    "#from matplotlib.axes import Axes\n",
    "#from cartopy.mpl.geoaxes import GeoAxes\n",
    "#GeoAxes._pcolormesh_patched = Axes.pcolormesh\n",
    "\n",
    "#remove warnings to improve display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#increase resolution for notebook outputs\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c3fe2",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "Try running this notebook in Google Colab! Toggle over the rocketship icon at the top of the page and click Colab to open a new window and run the notebook. <br><br>To run a single cell, type **Shift+Enter**. To run the whole notebook, under **Runtime** click **Run all**. Note that you will have to run the notebook from the very beginning and load all the Google Colab dependencies for the code to work.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f21db0",
   "metadata": {},
   "source": [
    "# Set desired date range \n",
    "Our analysis looks at winter data, so we'll only load data for the Northern Hemisphere winter season (Nov-Apr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8057a8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def getWinterDateRange(start_year, end_year, start_month = \"November\", end_month = \"April\"): \n",
    "    \"\"\" Gets date range for winter season/s\n",
    "    Calling the function for start_year=2018, end_year=2020, start_month=\"November\", end_month=\"April\" will generate a date range from Nov 2018-Apr 2019 and Nov 2019-Apr 2020\n",
    "    \n",
    "    Args: \n",
    "        start_year (str): start year \n",
    "        end_year (str): end year \n",
    "        start_month (str, optional): month at which winter starts (default to November)\n",
    "        end_month (str, optional): month at which winter ends (default to April)\n",
    "        \n",
    "    Returns: \n",
    "        winters (list): list of dates for all winter seasons in the input range (i.e: ['1980-11','1980-12','1981-01',\n",
    "         '1981-02','1981-03','1981-04')\n",
    "    \"\"\"\n",
    "    start_year = int(start_year)\n",
    "    end_year = int(end_year)\n",
    "    \n",
    "    winters = []\n",
    "    for year in range(start_year, end_year, 1):\n",
    "        winters += pd.date_range(start = str(year) + '-' + start_month,\n",
    "                                 end = str(year + 1) + '-' + end_month,\n",
    "                                 freq = 'MS')\n",
    "    winters = pd.to_datetime(winters)\n",
    "    return winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94edf94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-11-01', '2018-12-01', '2019-01-01', '2019-02-01',\n",
      "               '2019-03-01', '2019-04-01', '2019-11-01', '2019-12-01',\n",
      "               '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01'],\n",
      "              dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "start_year = \"2018\"\n",
    "end_year = \"2020\"\n",
    "winter_months = getWinterDateRange(start_year, end_year)\n",
    "print(winter_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb394e",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50eaaeb6",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def read_is2_data(data_dir=\"IS2SITMOGR4\"): \n",
    "    \"\"\" Read in ATLAS/ICESat-2 Monthly Gridded Sea Ice Freeboard dataset. \n",
    "    If the file does not already exist on the user's local drive, it is downloaded from the books google storage bucket (https://console.cloud.google.com/storage/browser/is2-pso-seaice)\n",
    "    The netcdf files for each month are then read in as an xr.Dataset object\n",
    "    \n",
    "    Args: \n",
    "        data_dir (str, optional): name of data directory containing ICESat-2 data (default to \"IS2SITMOGR4\", the name of the directory in the bucket)\n",
    "    Returns: \n",
    "        is2_ds (xr.Dataset): data \n",
    "    \n",
    "    \"\"\"\n",
    "    # Download data from bucket if it doesn't exist on the user's local drive\n",
    "    exists_locally = os.path.isdir(data_dir)\n",
    "    if (exists_locally == False): \n",
    "        print(\"Downloading ICESat-2 data from the google storage bucket...\")\n",
    "        os.system(\"gsutil -m cp -r gs://is2-pso-seaice/\" + data_dir + \" ./\") # Make sure theres a space before the final ./ (i.e. \" ./\")\n",
    "        print(\"Download complete\")\n",
    "\n",
    "    # Read in files for each month as a single xr.Dataset\n",
    "    # Need to create a preprocessing function to call before merging because dimensions and coordinates are not set\n",
    "    # This allows each DataArray for each month to be merged into one xr.Dataset\n",
    "    def xr_set_coords_and_dims(da_monthly):\n",
    "        da_monthly = da_monthly.set_coords([\"latitude\",\"longitude\",\"xgrid\",\"ygrid\"]) # Set data variables as coordinates\n",
    "        da_monthly = da_monthly.expand_dims(\"time\") # Set month as a dimension \n",
    "        return da_monthly\n",
    "    \n",
    "    filenames = os.listdir(data_dir)\n",
    "    is2_ds = xr.open_mfdataset([data_dir + \"/\" + filename for filename in filenames], # Filepath, including data directory in path\n",
    "                               concat_dim=[\"time\"], \n",
    "                               combine='nested', \n",
    "                               preprocess=xr_set_coords_and_dims)\n",
    "    time = [file.split(\"IS2SITMOGR4_01_\")[1].split(\"_004_001.nc\")[0] for file in filenames] # Get time from filenames\n",
    "    is2_ds = is2_ds.assign_coords({\"time\":pd.to_datetime(time, format = \"%Y%m\")}) # Add time as coordinate\n",
    "    return is2_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98eadcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ICESat-2 data from the google storage bucket...\n",
      "Download complete\n",
      "<xarray.Dataset>\n",
      "Dimensions:            (time: 12, x: 304, y: 448)\n",
      "Coordinates:\n",
      "    longitude          (y, x) float32 dask.array<chunksize=(448, 304), meta=np.ndarray>\n",
      "    latitude           (y, x) float32 dask.array<chunksize=(448, 304), meta=np.ndarray>\n",
      "    xgrid              (y, x) float32 dask.array<chunksize=(448, 304), meta=np.ndarray>\n",
      "    ygrid              (y, x) float32 dask.array<chunksize=(448, 304), meta=np.ndarray>\n",
      "  * time               (time) datetime64[ns] 2018-11-01 ... 2020-04-01\n",
      "Dimensions without coordinates: x, y\n",
      "Data variables:\n",
      "    projection         (time) int32 -2147483647 -2147483647 ... -2147483647\n",
      "    ice_thickness      (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    ice_thickness_unc  (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    num_segments       (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    mean_day_of_month  (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    snow_depth         (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    snow_density       (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    freeboard          (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    ice_type           (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "    ice_density        (time, y, x) float32 dask.array<chunksize=(1, 448, 304), meta=np.ndarray>\n",
      "Attributes:\n",
      "    contact:      Alek Petty (alek.a.petty@nasa.gov)\n",
      "    description:  Gridded Feb 2020 Arctic sea ice thickness and ancillary dat...\n",
      "    reference:    Data doi: 10.5067/CV6JEXEE31HF. Original methodology descri...\n",
      "    history:      Created 22/04/21\n"
     ]
    }
   ],
   "source": [
    "is2_ds = read_is2_data() # Read in data\n",
    "is2_ds = is2_ds.sel(time = winter_months) # Get winter months\n",
    "print(is2_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd4372d",
   "metadata": {},
   "source": [
    "# Set interpolation preferences  \n",
    "The dataset included uninterpolated data, or we can interpolate the data using a simple nearest neighbor interpolation function. Because ICESat-2 doesn't provide full monthly coverage, interpolating fills missing grid cells with a best guess based on surrounding data. This helps avoid sampling biases when performing time series analyses, with the cavaet that this interpolation method is subjective. <br><br>\n",
    "In order to definte the interpolation bounds (so that we don't try and interpolate over land, or other areas where there wouldn't be sea ice!), we use the [NOAA/NSIDC Climate Data Record of Passive Microwave Sea Ice Concentration](https://nsidc.org/data/g02202) dataset in order to infer the location of the sea ice. A version of this dataset is included in the netcdf file associated with the jupyter book. If the user wants to interpolate the ICESat-2 data, the NOAA/NSIDC sea ice concentration data will be downloaded from the jupyter book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a88f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14126405",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def read_book_data(filepath = \"icesat2-book-data.nc\"): \n",
    "    \"\"\" Read in data for ICESat2 jupyter book. \n",
    "    If the file does not already exist on the user's local drive, it is downloaded from the books google storage bucket (https://console.cloud.google.com/storage/browser/is2-pso-seaice)\n",
    "    The netcdf file is then read in as an xr.Dataset object \n",
    "    \n",
    "    Args: \n",
    "        filepath (str, optional): name of file to read in (default to \"icesat2-book-data.nc\", the name of the file in the bucket)\n",
    "    Returns: \n",
    "        book_ds (xr.Dataset): data \n",
    "    \n",
    "    \"\"\"\n",
    "    exists_locally = os.path.isfile(filepath) # Check if file exists on local drive\n",
    "    if (exists_locally == False): # Download data \n",
    "        print(\"Downloading jupyter book data from the google storage bucket...\")\n",
    "        os.system(\"gsutil -m cp gs://is2-pso-seaice/\" + filepath + \" ./\") # Make sure theres a space before the final ./ (i.e. \" ./\")\n",
    "        print(\"Download complete\")\n",
    "\n",
    "    book_ds = xr.open_dataset(filepath)\n",
    "    return book_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334292fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading jupyter book data from the google storage bucket...\n",
      "Download complete\n"
     ]
    }
   ],
   "source": [
    "if interpolate == True: \n",
    "    cdr_ds = read_book_data()[\"seaice_conc_monthly_cdr\"] # Get CDR data\n",
    "    cdr_ds = cdr_ds.sel(time = winter_months) # Get winter months\n",
    "    #is2_interp = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94953cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if interpolate == True: \n",
    "    is2_ds = interpolate_is2(is2_data = is2_ds, seaice_cdr = cdr_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few variables of interest\n",
    "data_vars = [\"ice_thickness\",\"ice_thickness_unc\",\"ice_type\",\"freeboard\"]\n",
    "is2_ds = is2_ds[data_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = is2_ds.longitude.values\n",
    "lats = is2_ds.latitude.values\n",
    "\n",
    "\n",
    "var = \"ice_thickness\"\n",
    "var_interp_list = []\n",
    "method = 'linear'\n",
    "for month in is2_ds.time.values: \n",
    "    da = is2_ds[var].sel(time = month) # Select just one month of data\n",
    "    np_da = da.values\n",
    "    np_interp = griddata((lons[~np.isnan(np_da)], lats[~np.isnan(np_da)]), # Interpolate\n",
    "                          np_da[~np.isnan(np_da)].flatten(),\n",
    "                          (lons, lats), \n",
    "                          fill_value=np.nan,\n",
    "                          method=method)\n",
    "    da_interp = xr.DataArray(data=np_interp, # convert numpy array --> xr.DataArray\n",
    "                             dims=da.dims, \n",
    "                             coords=da.coords,\n",
    "                             attrs={**da.attrs,'interpolation_method':method},\n",
    "                             name=da.name)\n",
    "    da_interp = da_interp.expand_dims(\"time\") # Add time as a dimension. Allows for merging DataArrays \n",
    "    var_interp_list.append(da_interp)\n",
    "var_interp = xr.merge(var_interp_list)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
